{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjjhxC1HuxOHbvzfNAhYp9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preethir-18/Complex-Network-Analysis/blob/main/ComCog_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPXtOdegl_PO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7222b99b-5e50-4803-ba95-39d9c8bd4d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne\n",
        "!pip install mat73\n",
        "!pip install mne_connectivity\n",
        "!pip install networkx"
      ],
      "metadata": {
        "id": "q2eH1HLCmPyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import mne\n",
        "from scipy.io import loadmat\n",
        "import mat73\n",
        "from matplotlib import pyplot as plt \n",
        "from mne_connectivity import spectral_connectivity_epochs\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import networkx.algorithms.community as nx_comm\n",
        "from networkx.algorithms.community import greedy_modularity_communities\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "Wilr-f0YmWpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mne.set_log_level('error')"
      ],
      "metadata": {
        "id": "seYQ3i4GqmEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing data of subject 1\n",
        "data = mat73.loadmat(r\"/content/drive/MyDrive/ComCog Project Data/music_listening_experiment_s01.mat\", only_include = None)"
      ],
      "metadata": {
        "id": "92OSNen0mZHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.keys()"
      ],
      "metadata": {
        "id": "asaRIU0Mp05f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f17a18-7c55-40e9-c4d1-3e26baea9356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['EEG_Rest', 'EEG_Songs', 'Fs', 'sensor_info', 'song_ratings'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eeg_songs = data['EEG_Songs']\n",
        "s_freq = data['Fs']  #sampling frequency = 128\n",
        "channel=['AF3','F7','F3','FC5','T7','P7','O1','O2','P8','T8','FC6','F4','F8','AF4']\n",
        "ch_name = np.array(channel)"
      ],
      "metadata": {
        "id": "Qi8j71clmgP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eeg_song = dict()\n",
        "for  song_no in range(30):  #30 songs are used in the study\n",
        "  eeg_songs = ((data['EEG_Songs'])[song_no])\n",
        "  eeg_song[song_no] = eeg_songs\n",
        "  eeg_songs = np.empty((14, 10240))\n",
        "\n",
        "s_rate_list = data['song_ratings']"
      ],
      "metadata": {
        "id": "hgtEdrYtxDrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rate_1 = []\n",
        "rate_5 = []\n",
        "for i in range(30):\n",
        "  if(s_rate_list[i] == 1):\n",
        "    rate_1.append(i)\n",
        "  elif(s_rate_list[i] == 5):\n",
        "    rate_5.append(i)\n"
      ],
      "metadata": {
        "id": "NNQRpZrd7c5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONNECTIVITY MATRICES"
      ],
      "metadata": {
        "id": "DKwAvcxbtwMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#epoching the given data\n",
        "epoch = dict()\n",
        "for song_no in range(30):\n",
        "  epochs=np.empty((80,14,128))\n",
        "  a=0\n",
        "  b=128\n",
        "  for i in range(80):\n",
        "    for j in range(14):\n",
        "      channels = (eeg_song[song_no])[j]\n",
        "      seg = np.array(channels[a:b])\n",
        "      for k in range(128):\n",
        "        epochs[i,j,k] = seg[k]\n",
        "    a=b\n",
        "    b=a+128\n",
        "    epoch[song_no] = epochs"
      ],
      "metadata": {
        "id": "yRXwh4ww0vYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lower and Upper frequency band of interest\n",
        "fmin = 30.0\n",
        "fmax = 45.0"
      ],
      "metadata": {
        "id": "wcUvxG96p41Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing WPLI for each phase relationship\n",
        "matrix = dict()\n",
        "for song_no in range(30):\n",
        "  matrices = spectral_connectivity_epochs(epoch[song_no], names=ch_name, method='wpli', indices=None, sfreq=s_freq,fmin=fmin,fmax=fmax,faverage=True)\n",
        "  matrix[song_no] = matrices\n"
      ],
      "metadata": {
        "id": "TfGrwMx1w9sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Connectivity matrix computed using WPLI\n",
        "\n",
        "conmat = dict()\n",
        "\n",
        "for song_no in range(30):\n",
        "  conmats = matrix[song_no].get_data(output='dense')[:, :, 0]\n",
        "  conmat[song_no] = conmats"
      ],
      "metadata": {
        "id": "-rFkNJpg3lbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#conmat[0]"
      ],
      "metadata": {
        "id": "eH2ZwPBoWosC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing the connectivity matrics for all songs after applying different thresholds\n",
        "\n",
        "threshold_mat = dict()\n",
        "\n",
        "threshold = [0.2, 0.3]\n",
        "\n",
        "for song_no in range(30):\n",
        "  thresh_mat = dict()\n",
        "  conmat_new = np.empty((14,14))\n",
        "  for value in threshold:\n",
        "    for i in range(14):\n",
        "      for j in range(14):\n",
        "        if((conmat[song_no])[i, j] >= value):\n",
        "          conmat_new[i, j] = (conmat[song_no])[i, j]\n",
        "        else:\n",
        "          conmat_new[i, j] = 0.0\n",
        "    thresh_mat[value] = conmat_new\n",
        "    conmat_new = np.empty((14,14))\n",
        "  threshold_mat[song_no] = thresh_mat\n",
        "  thresh_mat = dict()"
      ],
      "metadata": {
        "id": "71BDgKTw4P4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#threshold_mat[0]"
      ],
      "metadata": {
        "id": "DwVXtPA_VOUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = (np.array((threshold_mat[0])[0.3]))\n",
        "cmat = pd.DataFrame(temp, index=channel, columns=channel)\n",
        "\n",
        "my_palette = dict(zip(cmat.AF3.unique(), [\"orange\",\"yellow\",\"brown\"]))\n",
        "row_colors = cmat.AF3.map(my_palette)"
      ],
      "metadata": {
        "id": "Y_nW2TIzhwML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cmat"
      ],
      "metadata": {
        "id": "BjMyjKsCTpfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PLOTTING THE GRAPHS"
      ],
      "metadata": {
        "id": "QIHanxontPSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mne.viz import circular_layout\n",
        "from mne_connectivity.viz import plot_connectivity_circle"
      ],
      "metadata": {
        "id": "HwLeD5uHlp7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = dict()"
      ],
      "metadata": {
        "id": "mqjFLiGZ0l6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing the graphs for all the songs for different set thresholds\n",
        "\n",
        "graph_all = dict()\n",
        "for thresh in threshold:\n",
        "  graph_temp = dict()\n",
        "  for song_no in range(30):\n",
        "    temp = np.array((threshold_mat[song_no])[thresh])\n",
        "    G = nx.from_numpy_matrix(temp)\n",
        "    label_mapping = dict(zip(G.nodes(),ch_name))\n",
        "    H = nx.relabel_nodes(G, label_mapping)\n",
        "\n",
        "    H1 = nx.to_numpy_array(H)\n",
        "    graph_temp[song_no] = H1\n",
        "    H1 = np.zeros((14,14))\n",
        "  graph_all[thresh] = graph_temp"
      ],
      "metadata": {
        "id": "KJWQhqRF-i4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_list = [i+1 for i in range(14)]\n",
        "node_list"
      ],
      "metadata": {
        "id": "-KCo0UACxPba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c4caa50-ef2e-4637-b29e-fd9343d99d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from networkx.algorithms import community\n",
        "from statistics import mean"
      ],
      "metadata": {
        "id": "pSVgqBNOA8vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nx.is_connected((nx.from_numpy_matrix(graph_all[0.3][1]))))"
      ],
      "metadata": {
        "id": "p_hZ6HfrMst9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c085ec9-b522-46dd-b6f9-c34110676e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#(graph_all[0.3][0])"
      ],
      "metadata": {
        "id": "KIiXfx7QU2Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clustering = {'Threshold' : threshold}\n",
        "CPL = {'Threshold' : threshold}\n",
        "edge_cent = {'Threshold' : threshold}\n",
        "node_cent = {'Threshold' : threshold}\n",
        "modularity = {'Threshold' : threshold}\n",
        "\n",
        "for song_no in rate_1: \n",
        "  acc = [] #acc - average clustering coefficient\n",
        "  cp_len = [] #cp_len - characteristic path length\n",
        "  edbc_avg = [] #edbc_avg - edge_betweenness_centrality\n",
        "  ndbc_avg = [] #ndbc_avg - Node Betweenness centrality\n",
        "  mod = [] #Modularity\n",
        "  for thresh in threshold:\n",
        "    temp = (graph_all[thresh])[song_no]\n",
        "    G = nx.from_numpy_matrix(temp)\n",
        "    label_mapping = dict(zip(G.nodes(),node_list))\n",
        "    H = nx.relabel_nodes(G, label_mapping)\n",
        "\n",
        "    #Calculating Average Clustering Coefficient\n",
        "    clus = nx.average_clustering(H)\n",
        "    acc.append(clus)\n",
        "\n",
        "    #Calculating Path length and averaging them as it is not a complete graph\n",
        "    spl = dict(nx.shortest_path_length(H))\n",
        "    sum=0\n",
        "    c=0\n",
        "    for i in node_list:\n",
        "      value = dict() \n",
        "      key = spl[i].keys()\n",
        "      for j in node_list:\n",
        "        if(j in key):\n",
        "          sum = sum+spl[i][j]\n",
        "          c=c+1\n",
        "        else:\n",
        "          continue\n",
        "    avg_pl = sum/c\n",
        "    cp_len.append(avg_pl)\n",
        "\n",
        "    #Calculating Edge Betweenness Centrality\n",
        "    edbc = mean(nx.edge_betweenness_centrality(H).values())\n",
        "    edbc_avg.append(edbc)\n",
        "    #print(edbc)\n",
        "\n",
        "    #Calculating Node Betweenness Centrality\n",
        "    ndbc = mean(nx.betweenness_centrality(H).values())\n",
        "    ndbc_avg.append(ndbc)\n",
        "\n",
        "    #Modularity\n",
        "    feature_matrix=[]\n",
        "    communities = sorted(nx_comm.greedy_modularity_communities(H,weight='weight'), key=len, reverse=True)\n",
        "    feature_matrix.append(len(communities))\n",
        "    feature_matrix.append(nx_comm.modularity(H,communities,weight='weight'))\n",
        "    mod.append(feature_matrix[1])\n",
        "\n",
        "\n",
        "  clustering[(song_no+1)] = acc\n",
        "  CPL[(song_no+1)] = cp_len\n",
        "  edge_cent[(song_no+1)] = edbc_avg\n",
        "  node_cent[(song_no+1)] = ndbc_avg\n",
        "  modularity[(song_no+1)] = mod\n",
        "\n",
        "df = pd.DataFrame(clustering)\n",
        "df1 = pd.DataFrame(CPL)\n",
        "df2 = pd.DataFrame(edge_cent)\n",
        "df3 = pd.DataFrame(node_cent)\n",
        "df4 = pd.DataFrame(modularity)\n",
        "\n",
        "with pd.ExcelWriter('Songs-Rating1 Sub9.xlsx') as writer:\n",
        "  df.to_excel(writer, sheet_name=\"Average Clustering Coefficient\", index=False)\n",
        "  df1.to_excel(writer, sheet_name=\"Characteristic Path Length\", index=False)\n",
        "  df2.to_excel(writer, sheet_name=\"Edge Betweenness Centrality\", index=False)\n",
        "  df3.to_excel(writer, sheet_name=\"Node Betweenness Centrality\", index=False)\n",
        "  df4.to_excel(writer, sheet_name=\"Modularity\", index=False)\n"
      ],
      "metadata": {
        "id": "iZAfYZWQ9qrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clustering = {'Threshold' : threshold}\n",
        "CPL = {'Threshold' : threshold}\n",
        "edge_cent = {'Threshold' : threshold}\n",
        "node_cent = {'Threshold' : threshold}\n",
        "modularity = {'Threshold' : threshold}\n",
        "\n",
        "for song_no in rate_5: \n",
        "  acc = [] #acc - average clustering coefficient\n",
        "  cp_len = [] #cp_len - characteristic path length\n",
        "  edbc_avg = [] #edbc_avg - edge_betweenness_centrality\n",
        "  ndbc_avg = [] #ndbc_avg - Node Betweenness centrality\n",
        "  mod = [] #Modularity\n",
        "  for thresh in threshold:\n",
        "    temp = (graph_all[thresh])[song_no]\n",
        "    G = nx.from_numpy_matrix(temp)\n",
        "    label_mapping = dict(zip(G.nodes(),node_list))\n",
        "    H = nx.relabel_nodes(G, label_mapping)\n",
        "\n",
        "    #Calculating Average Clustering Coefficient\n",
        "    clus = nx.average_clustering(H)\n",
        "    acc.append(clus)\n",
        "\n",
        "    #Calculating Path length and averaging them as it is not a complete graph\n",
        "    spl = dict(nx.shortest_path_length(H))\n",
        "    sum=0\n",
        "    c=0\n",
        "    for i in node_list:\n",
        "      value = dict() \n",
        "      key = spl[i].keys()\n",
        "      for j in node_list:\n",
        "        if(j in key):\n",
        "          sum = sum+spl[i][j]\n",
        "          c=c+1\n",
        "        else:\n",
        "          continue\n",
        "    avg_pl = sum/c\n",
        "    cp_len.append(avg_pl)\n",
        "\n",
        "    #Calculating Edge Betweenness Centrality\n",
        "    edbc = mean(nx.edge_betweenness_centrality(H).values())\n",
        "    edbc_avg.append(edbc)\n",
        "    #print(edbc)\n",
        "\n",
        "    #Calculating Node Betweenness Centrality\n",
        "    ndbc = mean(nx.betweenness_centrality(H).values())\n",
        "    ndbc_avg.append(ndbc)\n",
        "\n",
        "    #Modularity\n",
        "    feature_matrix=[]\n",
        "    communities = sorted(nx_comm.greedy_modularity_communities(H,weight='weight'), key=len, reverse=True)\n",
        "    feature_matrix.append(len(communities))\n",
        "    feature_matrix.append(nx_comm.modularity(H,communities,weight='weight'))\n",
        "    mod.append(feature_matrix[1])\n",
        "\n",
        "\n",
        "\n",
        "  clustering[(song_no+1)] = acc\n",
        "  CPL[(song_no+1)] = cp_len\n",
        "  edge_cent[(song_no+1)] = edbc_avg\n",
        "  node_cent[(song_no+1)] = ndbc_avg\n",
        "  modularity[(song_no+1)] = mod\n",
        "\n",
        "df = pd.DataFrame(clustering)\n",
        "df1 = pd.DataFrame(CPL)\n",
        "df2 = pd.DataFrame(edge_cent)\n",
        "df3 = pd.DataFrame(node_cent)\n",
        "df4 = pd.DataFrame(modularity)\n",
        "\n",
        "with pd.ExcelWriter('Songs-Rating5 Sub9.xlsx') as writer:\n",
        "  df.to_excel(writer, sheet_name=\"Average Clustering Coefficient\", index=False)\n",
        "  df1.to_excel(writer, sheet_name=\"Characteristic Path Length\", index=False)\n",
        "  df2.to_excel(writer, sheet_name=\"Edge Betweenness Centrality\", index=False)\n",
        "  df3.to_excel(writer, sheet_name=\"Node Betweenness Centrality\", index=False)\n",
        "  df4.to_excel(writer, sheet_name=\"Modularity\", index=False)\n"
      ],
      "metadata": {
        "id": "XmhgNiLkwP-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = pd.read_csv(r\"/content/Average CC.csv\")\n",
        "df_new.head()\n",
        "sns.set(style='whitegrid')\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "g = sns.boxplot(data=df_new, width = 0.4)\n",
        "plt.title('Average CC')\n",
        "plt.ylabel('WPLI')\n",
        "plt.savefig(\"Boxplot CC.png\")"
      ],
      "metadata": {
        "id": "jnfGiEdjpPof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = pd.read_csv(r\"/content/Average CPL.csv\")\n",
        "df_new.head()\n",
        "sns.set(style='whitegrid')\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "g = sns.boxplot(data=df_new, width = 0.4)\n",
        "plt.title('Average CPL')\n",
        "plt.ylabel('WPLI')\n",
        "plt.savefig(\"Boxplot CPL.png\")\n"
      ],
      "metadata": {
        "id": "mrMDbxKS3okm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = pd.read_excel(r\"/content/Average EBC.xlsx\")\n",
        "df_new.head()\n",
        "sns.set(style='whitegrid')\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "g = sns.boxplot(data=df_new, width = 0.4)\n",
        "plt.title('Average EBC')\n",
        "plt.ylabel('WPLI')\n",
        "plt.savefig(\"Boxplot EBC.png\")\n"
      ],
      "metadata": {
        "id": "6M4ZOx4P5yNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = pd.read_excel(r\"/content/Average EBC.xlsx\")\n",
        "df_new.head()\n",
        "sns.set(style='whitegrid')\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "g = sns.boxplot(data=df_new, width = 0.4)\n",
        "plt.title('Average EBC')\n",
        "plt.ylabel('WPLI')\n",
        "plt.savefig(\"Boxplot EBC.png\")\n"
      ],
      "metadata": {
        "id": "CC595jtd6j6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = pd.read_excel(r\"/content/Average NBC.xlsx\")\n",
        "df_new.head()\n",
        "sns.set(style='whitegrid')\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "g = sns.boxplot(data=df_new, width = 0.4)\n",
        "plt.title('Average NBC')\n",
        "plt.ylabel('WPLI')\n",
        "plt.savefig(\"Boxplot NBC.png\")"
      ],
      "metadata": {
        "id": "b14ioob36-Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = pd.read_excel(r\"/content/Average Modularity.xlsx\")\n",
        "df_new.head()\n",
        "sns.set(style='whitegrid')\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "g = sns.boxplot(data=df_new, width = 0.4)\n",
        "plt.title('Average Modularity')\n",
        "plt.ylabel('WPLI')\n",
        "plt.savefig(\"Boxplot Modularity.png\")"
      ],
      "metadata": {
        "id": "qWXZb-9Q7Cbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = graph_all[0.3][0]\n",
        "G = nx.from_numpy_matrix(temp)\n",
        "label_mapping = dict(zip(G.nodes(),channel))\n",
        "H = nx.relabel_nodes(G, label_mapping)\n",
        "#nx.draw_networkx(H, pos = nx.circular_layout(H), label=True, node_size=600)\n",
        "\n",
        "dgc = nx.degree_centrality(H)\n",
        "df1 = pd.DataFrame(dgc, index=[1])\n",
        "\n",
        "edbc = nx.edge_betweenness_centrality(H)\n",
        "df2 = pd.DataFrame(edbc, index=[1])\n",
        "\n",
        "nbc = nx.betweenness_centrality(H)\n",
        "df3 = pd.DataFrame(nbc, index=[1])\n",
        "\n",
        "with pd.ExcelWriter('NODE WISE DATA SONG 1.xlsx') as writer:\n",
        "  df1.to_excel(writer, sheet_name=\"Degree Centrality\")\n",
        "  df2.to_excel(writer, sheet_name=\"Edge Betweeness Centrality\")\n",
        "  df3.to_excel(writer, sheet_name=\"Node Betweeness Centrality\")\n",
        "\n",
        "\n",
        "temp = graph_all[0.3][10]\n",
        "G = nx.from_numpy_matrix(temp)\n",
        "label_mapping = dict(zip(G.nodes(),channel))\n",
        "H = nx.relabel_nodes(G, label_mapping)\n",
        "#nx.draw_networkx(H, pos = nx.circular_layout(H), label=True, node_size=600)\n",
        "\n",
        "dgc = nx.degree_centrality(H)\n",
        "df1 = pd.DataFrame(dgc, index=[1])\n",
        "\n",
        "edbc = nx.edge_betweenness_centrality(H)\n",
        "df2 = pd.DataFrame(edbc, index=[1])\n",
        "\n",
        "nbc = nx.betweenness_centrality(H)\n",
        "df3 = pd.DataFrame(nbc, index=[1])\n",
        "\n",
        "with pd.ExcelWriter('NODE WISE DATA SONG 5.xlsx') as writer:\n",
        "  df1.to_excel(writer, sheet_name=\"Degree Centrality\")\n",
        "  df2.to_excel(writer, sheet_name=\"Edge Betweeness Centrality\")\n",
        "  df3.to_excel(writer, sheet_name=\"Node Betweeness Centrality\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3FlMlXeDJ7ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dg_cent = {}\n",
        "for song_no in rate_1:\n",
        "  dgc = []\n",
        "  temp = graph_all[0.3][song_no]\n",
        "  G = nx.from_numpy_matrix(temp)\n",
        "  label_mapping = dict(zip(G.nodes(),channel))\n",
        "  H = nx.relabel_nodes(G, label_mapping)\n",
        "  #nx.draw_networkx(H, pos = nx.circular_layout(H), label=True, node_size=600)\n",
        "\n",
        "  dgc = nx.degree_centrality(H)\n",
        "  dg_cent[song_no] = dgc\n",
        "df = pd.DataFrame(dg_cent)\n",
        "\n",
        "for song_no in rate_5:\n",
        "  dgc = []\n",
        "  temp = graph_all[0.3][song_no]\n",
        "  G = nx.from_numpy_matrix(temp)\n",
        "  label_mapping = dict(zip(G.nodes(),channel))\n",
        "  H = nx.relabel_nodes(G, label_mapping)\n",
        "  #nx.draw_networkx(H, pos = nx.circular_layout(H), label=True, node_size=600)\n",
        "\n",
        "  dgc = nx.degree_centrality(H)\n",
        "  dg_cent[song_no] = dgc\n",
        "df1 = pd.DataFrame(dg_cent)\n",
        "\n",
        "with pd.ExcelWriter('DEGREE CENTRALITY.xlsx') as writer:\n",
        "  df.to_excel(writer, sheet_name=\"RATING 1\")\n",
        "  df1.to_excel(writer, sheet_name=\"RATING 5\")"
      ],
      "metadata": {
        "id": "I-m6DK0hQD7A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}