{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ZRIizkOUiYsuJ7akMK05-i-AyoP0HwHG",
      "authorship_tag": "ABX9TyPppenm1gXE201G+G7zxWoS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preethir-18/Complex-Network-Analysis/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3mk2zQ6iDHy"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne\n",
        "!pip install mat73\n",
        "!pip install mne_connectivity\n",
        "!pip install networkx"
      ],
      "metadata": {
        "id": "gqRfeqjLiRtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import mne\n",
        "from scipy.io import loadmat\n",
        "import mat73\n",
        "from matplotlib import pyplot as plt \n",
        "from mne_connectivity import spectral_connectivity_epochs\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "from statistics import mean"
      ],
      "metadata": {
        "id": "2skhIZ49iWvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mne.set_log_level('error')"
      ],
      "metadata": {
        "id": "_rqDgf8wiZMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [1]:\n",
        "  path1 = \"/content/drive/MyDrive/ComCog Project Data/music_listening_experiment_s0\"\n",
        "  path2 = \".mat\"\n",
        "  path_final = path1+str(i+1)+path2\n",
        "  data =  mat73.loadmat(path_final)\n",
        "\n",
        "  eeg_songs = data['EEG_Songs']\n",
        "  s_freq = data['Fs']  #sampling frequency = 128\n",
        "  channel=['AF3','F7','F3','FC5','T7','P7','O1','O2','P8','T8','FC6','F4','F8','AF4']\n",
        "  ch_name = np.array(channel)\n",
        "\n",
        "  eeg_song = dict()\n",
        "  for  song_no in range(30):  #30 songs are used in the study\n",
        "    eeg_songs = ((data['EEG_Songs'])[song_no])\n",
        "    eeg_song[song_no] = eeg_songs\n",
        "    eeg_songs = np.empty((14, 10240))\n",
        "  s_rate_list = data['song_ratings']\n",
        "\n",
        "  rate_1 = []\n",
        "  rate_5 = []\n",
        "  for i in range(30):\n",
        "    if(s_rate_list[i] == 1):\n",
        "      rate_1.append(i)\n",
        "    elif(s_rate_list[i] == 5):\n",
        "      rate_5.append(i)\n",
        "\n",
        "  #epoching the given data\n",
        "  epoch = dict()\n",
        "  for song_no in range(30):\n",
        "    epochs=np.empty((80,14,128))\n",
        "    a=0\n",
        "    b=128\n",
        "    for i in range(80):\n",
        "      for j in range(14):\n",
        "        channels = (eeg_song[song_no])[j]\n",
        "        seg = np.array(channels[a:b])\n",
        "        for k in range(128):\n",
        "          epochs[i,j,k] = seg[k]\n",
        "      a=b\n",
        "      b=a+128\n",
        "      epoch[song_no] = epochs\n",
        "\n",
        "  #Lower and Upper frequency band of interest\n",
        "  fmin = [4.0,8.0]\n",
        "  fmax = [8.0,12.0]\n",
        "\n",
        "  #Computing WPLI for each phase relationship\n",
        "  matrix = dict()\n",
        "  for song_no in range(30):\n",
        "    matrices = spectral_connectivity_epochs(epoch[song_no], names=ch_name, method='wpli', indices=None, sfreq=s_freq,fmin=fmin,fmax=fmax,faverage=True)\n",
        "    matrix[song_no] = matrices\n",
        "\n",
        "  #Connectivity matrix computed using WPLI\n",
        "  conmat = dict()\n",
        "  for song_no in range(30):\n",
        "    conmats = matrix[song_no].get_data(output='dense')[:, :, 0]\n",
        "    conmat[song_no] = conmats\n",
        "\n",
        "  #Computing the connectivity matrics for all songs after applying different thresholds\n",
        "  threshold_mat = dict()\n",
        "  threshold = [0.2, 0.3, 0.4, 0.5]\n",
        "  for song_no in range(30):\n",
        "    thresh_mat = dict()\n",
        "    conmat_new = np.empty((14,14))\n",
        "    for value in threshold:\n",
        "      for i in range(14):\n",
        "        for j in range(14):\n",
        "          if((conmat[song_no])[i, j] >= value):\n",
        "            conmat_new[i, j] = (conmat[song_no])[i, j]\n",
        "          else:\n",
        "            conmat_new[i, j] = 0.0\n",
        "      thresh_mat[value] = conmat_new\n",
        "      conmat_new = np.empty((14,14))\n",
        "    threshold_mat[song_no] = thresh_mat\n",
        "    thresh_mat = dict()\n",
        "\n",
        "  #Computing the graphs for all the songs for different set thresholds\n",
        "  graph_all = dict()\n",
        "  for thresh in threshold:\n",
        "    graph_temp = dict()\n",
        "    for song_no in range(30):\n",
        "      temp = np.array((threshold_mat[song_no])[thresh])\n",
        "      G = nx.from_numpy_matrix(temp)\n",
        "      label_mapping = dict(zip(G.nodes(),ch_name))\n",
        "      H = nx.relabel_nodes(G, label_mapping)\n",
        "      H1 = nx.to_numpy_array(H)\n",
        "      graph_temp[song_no] = H1\n",
        "      H1 = np.zeros((14,14))\n",
        "    graph_all[thresh] = graph_temp\n",
        "\n",
        "  node_list = [i+1 for i in range(14)]\n",
        "  \n",
        "  clustering = {'Threshold' : threshold}\n",
        "  CPL = {'Threshold' : threshold}\n",
        "  edge_cent = {'Threshold' : threshold}\n",
        "  node_cent = {'Threshold' : threshold}\n",
        "  for song_no in rate_1: \n",
        "    acc = [] #acc - average clustering coefficient\n",
        "    cp_len = [] #cp_len - characteristic path length\n",
        "    edbc_avg = [] #edbc_avg - edge_betweenness_centrality\n",
        "    ndbc_avg = [] #ndbc_avg - Node Betweenness centrality\n",
        "    for thresh in threshold:\n",
        "      temp = (graph_all[thresh])[song_no]\n",
        "      G = nx.from_numpy_matrix(temp)\n",
        "      label_mapping = dict(zip(G.nodes(),node_list))\n",
        "      H = nx.relabel_nodes(G, label_mapping)\n",
        "\n",
        "      #Calculating Average Clustering Coefficient\n",
        "      clus = nx.average_clustering(H)\n",
        "      acc.append(clus)\n",
        "\n",
        "      #Calculating Path length and averaging them as it is not a complete graph\n",
        "      spl = dict(nx.shortest_path_length(H))\n",
        "      sum=0\n",
        "      c=0\n",
        "      for i in node_list:\n",
        "        value = dict() \n",
        "        key = spl[i].keys()\n",
        "        for j in node_list:\n",
        "          if(j in key):\n",
        "            sum = sum+spl[i][j]\n",
        "            c=c+1\n",
        "          else:\n",
        "            continue\n",
        "      avg_pl = sum/c\n",
        "      cp_len.append(avg_pl)\n",
        "\n",
        "      #Calculating Edge Betweenness Centrality\n",
        "      edbc = mean(nx.edge_betweenness_centrality(H).values())\n",
        "      edbc_avg.append(edbc)\n",
        "\n",
        "      #Calculating Node Betweenness Centrality\n",
        "      ndbc = mean(nx.betweenness_centrality(H).values())\n",
        "      ndbc_avg.append(ndbc)\n",
        "\n",
        "    clustering[(song_no+1)] = acc\n",
        "    CPL[(song_no+1)] = cp_len\n",
        "    edge_cent[(song_no+1)] = edbc_avg\n",
        "    node_cent[(song_no+1)] = ndbc_avg\n",
        "\n",
        "  df = pd.DataFrame(clustering)\n",
        "  df1 = pd.DataFrame(CPL)\n",
        "  df2 = pd.DataFrame(edge_cent)\n",
        "  df3 = pd.DataFrame(node_cent)\n",
        "\n",
        "  file1 = 'Subject '\n",
        "  file2 = ' Srate_1.xlsx'\n",
        "  file_name = file1+str(i+1)+file2\n",
        "\n",
        "  with pd.ExcelWriter(file_name) as writer:\n",
        "    df.to_excel(writer, sheet_name=\"Average Clustering Coefficient\", index=False)\n",
        "    df1.to_excel(writer, sheet_name=\"Characteristic Path Length\", index=False)\n",
        "    df2.to_excel(writer, sheet_name=\"Edge Betweenness Centrality\", index=False)\n",
        "    df3.to_excel(writer, sheet_name=\"Node Betweenness Centrality\", index=False)\n",
        "\n",
        "\n",
        "  clustering = {'Threshold' : threshold}\n",
        "  CPL = {'Threshold' : threshold}\n",
        "  edge_cent = {'Threshold' : threshold}\n",
        "  node_cent = {'Threshold' : threshold}\n",
        "\n",
        "  for song_no in rate_5: \n",
        "    acc = [] #acc - average clustering coefficient\n",
        "    cp_len = [] #cp_len - characteristic path length\n",
        "    edbc_avg = [] #edbc_avg - edge_betweenness_centrality\n",
        "    ndbc_avg = [] #ndbc_avg - Node Betweenness centrality\n",
        "    for thresh in threshold:\n",
        "      temp = (graph_all[thresh])[song_no]\n",
        "      G = nx.from_numpy_matrix(temp)\n",
        "      label_mapping = dict(zip(G.nodes(),node_list))\n",
        "      H = nx.relabel_nodes(G, label_mapping)\n",
        "\n",
        "      #C alculating Average Clustering Coefficient\n",
        "      clus = nx.average_clustering(H)\n",
        "      acc.append(clus)\n",
        "\n",
        "      #Calculating Path length and averaging them as it is not a complete graph\n",
        "      spl = dict(nx.shortest_path_length(H))\n",
        "      sum=0\n",
        "      c=0\n",
        "      for i in node_list:\n",
        "        value = dict() \n",
        "        key = spl[i].keys()\n",
        "        for j in node_list:\n",
        "          if(j in key):\n",
        "            sum = sum+spl[i][j]\n",
        "            c=c+1\n",
        "          else:\n",
        "            continue\n",
        "      avg_pl = sum/c\n",
        "      cp_len.append(avg_pl)\n",
        "\n",
        "      #Calculating Edge Betweenness Centrality\n",
        "      edbc = mean(nx.edge_betweenness_centrality(H).values())\n",
        "      edbc_avg.append(edbc)\n",
        "\n",
        "      #Calculating Node Betweenness Centrality\n",
        "      ndbc = mean(nx.betweenness_centrality(H).values())\n",
        "      ndbc_avg.append(ndbc)\n",
        "\n",
        "    clustering[(song_no+1)] = acc\n",
        "    CPL[(song_no+1)] = cp_len\n",
        "    edge_cent[(song_no+1)] = edbc_avg\n",
        "    node_cent[(song_no+1)] = ndbc_avg\n",
        "\n",
        "  df = pd.DataFrame(clustering)\n",
        "  df1 = pd.DataFrame(CPL)\n",
        "  df2 = pd.DataFrame(edge_cent)\n",
        "  df3 = pd.DataFrame(node_cent)\n",
        "\n",
        "  file1 = 'Subject '\n",
        "  file2 = ' Srate_5.xlsx'\n",
        "  fil_name = file1+str(i+1)+file2\n",
        "\n",
        "  with pd.ExcelWriter(fil_name) as writer:\n",
        "    df.to_excel(writer, sheet_name=\"Average Clustering Coefficient\", index=False)\n",
        "    df1.to_excel(writer, sheet_name=\"Characteristic Path Length\", index=False)\n",
        "    df2.to_excel(writer, sheet_name=\"Edge Betweenness Centrality\", index=False)\n",
        "    df3.to_excel(writer, sheet_name=\"Node Betweenness Centrality\", index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "A3VqQs4IiaDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clustering = {'Threshold' : threshold}\n",
        "CPL = {'Threshold' : threshold}\n",
        "edge_cent = {'Threshold' : threshold}\n",
        "node_cent = {'Threshold' : threshold}\n",
        "\n",
        "for song_no in rate_5: \n",
        "  acc = [] #acc - average clustering coefficient\n",
        "  cp_len = [] #cp_len - characteristic path length\n",
        "  edbc_avg = [] #edbc_avg - edge_betweenness_centrality\n",
        "  ndbc_avg = [] #ndbc_avg - Node Betweenness centrality\n",
        "  for thresh in threshold:\n",
        "    temp = (graph_all[thresh])[song_no]\n",
        "    G = nx.from_numpy_matrix(temp)\n",
        "    label_mapping = dict(zip(G.nodes(),node_list))\n",
        "    H = nx.relabel_nodes(G, label_mapping)\n",
        "\n",
        "    #Calculating Average Clustering Coefficient\n",
        "    clus = nx.average_clustering(H)\n",
        "    acc.append(clus)\n",
        "\n",
        "    #Calculating Path length and averaging them as it is not a complete graph\n",
        "    spl = dict(nx.shortest_path_length(H))\n",
        "    sum=0\n",
        "    c=0\n",
        "    for i in node_list:\n",
        "      value = dict() \n",
        "      key = spl[i].keys()\n",
        "      for j in node_list:\n",
        "        if(j in key):\n",
        "          sum = sum+spl[i][j]\n",
        "          c=c+1\n",
        "        else:\n",
        "          continue\n",
        "    avg_pl = sum/c\n",
        "    cp_len.append(avg_pl)\n",
        "\n",
        "    #Calculating Edge Betweenness Centrality\n",
        "    edbc = mean(nx.edge_betweenness_centrality(H).values())\n",
        "    edbc_avg.append(edbc)\n",
        "\n",
        "    #Calculating Node Betweenness Centrality\n",
        "    ndbc = mean(nx.betweenness_centrality(H).values())\n",
        "    ndbc_avg.append(ndbc)\n",
        "\n",
        "  clustering[(song_no+1)] = acc\n",
        "  CPL[(song_no+1)] = cp_len\n",
        "  edge_cent[(song_no+1)] = edbc_avg\n",
        "  node_cent[(song_no+1)] = ndbc_avg\n",
        "\n",
        "df = pd.DataFrame(clustering)\n",
        "df1 = pd.DataFrame(CPL)\n",
        "df2 = pd.DataFrame(edge_cent)\n",
        "df3 = pd.DataFrame(node_cent)\n",
        "\n",
        "with pd.ExcelWriter('Song-Rating5.xlsx') as writer:\n",
        "  df.to_excel(writer, sheet_name=\"Average Clustering Coefficient\", index=False)\n",
        "  df1.to_excel(writer, sheet_name=\"Characteristic Path Length\", index=False)\n",
        "  df2.to_excel(writer, sheet_name=\"Edge Betweenness Centrality\", index=False)\n",
        "  df3.to_excel(writer, sheet_name=\"Node Betweenness Centrality\", index=False)\n"
      ],
      "metadata": {
        "id": "lvV06oc9xO_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the graph and circular connectivity for 2 songs after taking inputs from the user. \n",
        "\n",
        "def plot_graph(song_no1,song_no2, thresh):\n",
        "  for song_no in [song_no1, song_no2]:\n",
        "    temp = np.array((threshold_mat[(song_no-1)])[thresh])\n",
        "    G = nx.from_numpy_matrix(temp)\n",
        "    label_mapping = dict(zip(G.nodes(),ch_name))\n",
        "    H = nx.relabel_nodes(G, label_mapping)\n",
        "\n",
        "    H1 = nx.to_numpy_array(H)\n",
        "    graph[song_no] = H1\n",
        "    H1 = np.zeros((14,14))\n",
        "\n",
        "    all_weights=[]\n",
        "    for (node1,node2,data) in H.edges(data=True):\n",
        "        all_weights.append(data['weight'])\n",
        "    unique_weights = list(set(all_weights))\n",
        "    widths=[]\n",
        "    for weight in unique_weights:\n",
        "          #4 d. Form a filtered list with just the weight you want to draw\n",
        "          weighted_edges = [(node1,node2) for (node1,node2,edge_attr) in H.edges(data=True) if edge_attr['weight']==weight]\n",
        "          width = weight*len(G.nodes())*5.0/sum(all_weights)\n",
        "          widths.append(width)\n",
        "    nx.draw_networkx(H, pos=nx.spring_layout(H), with_labels=True, width=widths, node_size=600)\n",
        "\n",
        "    plt.draw() \n",
        "    plt.title('Graph for song '+str(song_no)+' after applying a threshold of '+ str(thresh), loc='center')\n",
        "    plt.show()\n",
        "\n",
        "    node_colors={'red','blue','green','yellow','white','gray','orange','purple','brown','pink','olive','cyan','indigo','turquoise'}\n",
        "    fig, ax = plt.subplots(figsize=(8, 8), facecolor='black',\n",
        "                        subplot_kw=dict(polar=True))\n",
        "    plot_connectivity_circle(temp, channel, n_lines=300, node_angles=None, node_colors=node_colors, \n",
        "                          title='Circular (WPLI) Connectivity for song '+str(song_no)+' after applying a threshold of '+ str(thresh), ax=ax)\n",
        "    fig.tight_layout()\n",
        "\n",
        "song_no1 = int(input(\"Enter the Song number for first graph \"))\n",
        "song_no2 = int(input(\"Enter the Song number for second graph \"))\n",
        "thresh = float(input(\"Choose a threshold from 0.2, 0.3, 0.4, 0.5 \"))\n",
        "\n",
        "plot_graph(song_no1, song_no2, thresh)"
      ],
      "metadata": {
        "id": "cPwKYtuUxULq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}